==> Start training ...
Training Epoch: 0 | Loss: 0.953469380736351
Training Epoch: 0 | Loss: 0.6861794490256522
Training Epoch: 0 | Loss: 0.6725936598000835
Training Epoch: 0 | Loss: 0.6470180331695318
Training Epoch: 0 | Loss: 0.6287473502877793
Training Epoch: 0 | Loss: 0.6152644900980586
Training Epoch: 0 | Loss: 0.603325215668825
Training Epoch: 0 | Loss: 0.5928140125275934
Training Epoch: 0 | Loss: 0.5884535856470559
Validation Loss: 0.6994361132383347
Validation Loss: 0.5184076431732957
Validation Loss: 0.5303398430050902

==> Save checkpoint ...
Training Epoch: 1 | Loss: 0.3985874280333519
Training Epoch: 1 | Loss: 0.5365905520496982
Training Epoch: 1 | Loss: 0.5359959922805058
Training Epoch: 1 | Loss: 0.5329775986852638
Training Epoch: 1 | Loss: 0.5241810958971852
Training Epoch: 1 | Loss: 0.519882637709974
Training Epoch: 1 | Loss: 0.5210092183289284
Training Epoch: 1 | Loss: 0.5198883437677772
Training Epoch: 1 | Loss: 0.5177908027649261
Validation Loss: 0.6050058305263519
Validation Loss: 0.5380768722826892
Validation Loss: 0.5291636194199768

Training Epoch: 2 | Loss: 0.551101066172123
Training Epoch: 2 | Loss: 0.5193698986774624
Training Epoch: 2 | Loss: 0.5039630308654622
Training Epoch: 2 | Loss: 0.5043082604265193
Training Epoch: 2 | Loss: 0.5006559130101653
Training Epoch: 2 | Loss: 0.5020244027452614
Training Epoch: 2 | Loss: 0.4999627181221909
Training Epoch: 2 | Loss: 0.49781936330829724
Training Epoch: 2 | Loss: 0.49641892743923616
Validation Loss: 0.6164734959602356
Validation Loss: 0.4912473181686779
Validation Loss: 0.48708790596296536

Training Epoch: 3 | Loss: 0.5714541077613831
Training Epoch: 3 | Loss: 0.47045629102699826
Training Epoch: 3 | Loss: 0.47286360929557936
Training Epoch: 3 | Loss: 0.47574792051087583
Training Epoch: 3 | Loss: 0.4771863645003026
Training Epoch: 3 | Loss: 0.47692525873849256
Training Epoch: 3 | Loss: 0.4762698175717213
Training Epoch: 3 | Loss: 0.47566080892115786
Training Epoch: 3 | Loss: 0.47756524405415435
Validation Loss: 0.5687066838145256
Validation Loss: 0.466776781300507
Validation Loss: 0.46778897883657794

Training Epoch: 4 | Loss: 0.4341123551130295
Training Epoch: 4 | Loss: 0.46176862890029896
Training Epoch: 4 | Loss: 0.4742794611412494
Training Epoch: 4 | Loss: 0.46875123127651375
Training Epoch: 4 | Loss: 0.466057026540475
Training Epoch: 4 | Loss: 0.4671364503721158
Training Epoch: 4 | Loss: 0.4660466250943364
Training Epoch: 4 | Loss: 0.46582970629511306
Training Epoch: 4 | Loss: 0.4636562727066164
Validation Loss: 0.41699718683958054
Validation Loss: 0.4442285468598994
Validation Loss: 0.45929157543945964

Training Epoch: 5 | Loss: 0.4456002041697502
Training Epoch: 5 | Loss: 0.45809488994355246
Training Epoch: 5 | Loss: 0.4545918579273556
Training Epoch: 5 | Loss: 0.4507427048990101
Training Epoch: 5 | Loss: 0.4509395884113047
Training Epoch: 5 | Loss: 0.4512694519712123
Training Epoch: 5 | Loss: 0.44883105875040946
Training Epoch: 5 | Loss: 0.44889496104491505
Training Epoch: 5 | Loss: 0.4496303889993462
Validation Loss: 0.5033595860004425
Validation Loss: 0.43575310323498034
Validation Loss: 0.43785159523362543

==> Save checkpoint ...
Training Epoch: 6 | Loss: 0.4037835821509361
Training Epoch: 6 | Loss: 0.44353251350988254
Training Epoch: 6 | Loss: 0.4440273807119967
Training Epoch: 6 | Loss: 0.4405788416630802
Training Epoch: 6 | Loss: 0.440512615202594
Training Epoch: 6 | Loss: 0.44128813762626723
Training Epoch: 6 | Loss: 0.4404416511985109
Training Epoch: 6 | Loss: 0.4403474334781503
Training Epoch: 6 | Loss: 0.43980496148166065
Validation Loss: 0.3603140637278557
Validation Loss: 0.43174613735610895
Validation Loss: 0.43774553746059164

Training Epoch: 7 | Loss: 0.3356030806899071
Training Epoch: 7 | Loss: 0.43165080374715353
Training Epoch: 7 | Loss: 0.43069508203782547
Training Epoch: 7 | Loss: 0.4338334143669205
Training Epoch: 7 | Loss: 0.4345416895478518
Training Epoch: 7 | Loss: 0.43377917250636927
Training Epoch: 7 | Loss: 0.4315138809823008
Training Epoch: 7 | Loss: 0.43021591883232435
Training Epoch: 7 | Loss: 0.429737504750732
Validation Loss: 0.2954689636826515
Validation Loss: 0.4393711044351653
Validation Loss: 0.4395516777031161

Training Epoch: 8 | Loss: 0.5494457557797432
Training Epoch: 8 | Loss: 0.4249949181765908
Training Epoch: 8 | Loss: 0.4173879014300321
Training Epoch: 8 | Loss: 0.4177774296040056
Training Epoch: 8 | Loss: 0.4185196941026354
Training Epoch: 8 | Loss: 0.41797018226630195
Training Epoch: 8 | Loss: 0.4196406326778915
Training Epoch: 8 | Loss: 0.4215465049696462
Training Epoch: 8 | Loss: 0.4215461206849148
Validation Loss: 0.36176127195358276
Validation Loss: 0.41257462919791144
Validation Loss: 0.42017143825764086

Training Epoch: 9 | Loss: 0.46350087970495224
Training Epoch: 9 | Loss: 0.4387481893495758
Training Epoch: 9 | Loss: 0.4239574832035534
Training Epoch: 9 | Loss: 0.41914746360822375
Training Epoch: 9 | Loss: 0.41727547601627146
Training Epoch: 9 | Loss: 0.4137540044088266
Training Epoch: 9 | Loss: 0.4136169759863476
Training Epoch: 9 | Loss: 0.41431577086778154
Training Epoch: 9 | Loss: 0.41293150993219846
Validation Loss: 0.3549289293587208
Validation Loss: 0.4042904420506836
Validation Loss: 0.4078107496436259

Training Epoch: 10 | Loss: 0.264737319201231
Training Epoch: 10 | Loss: 0.39328719085395925
Training Epoch: 10 | Loss: 0.39972286954966946
Training Epoch: 10 | Loss: 0.39922406194589266
Training Epoch: 10 | Loss: 0.40407681656987443
Training Epoch: 10 | Loss: 0.40226322103537127
Training Epoch: 10 | Loss: 0.4037666530464582
Training Epoch: 10 | Loss: 0.4043679407448342
Training Epoch: 10 | Loss: 0.4030466105779645
Validation Loss: 0.4586842879652977
Validation Loss: 0.4143185446979386
Validation Loss: 0.4080059761135139

==> Save checkpoint ...
Training Epoch: 11 | Loss: 0.31013794988393784
Training Epoch: 11 | Loss: 0.3862528961778867
Training Epoch: 11 | Loss: 0.3892293073311077
Training Epoch: 11 | Loss: 0.3898958129022407
Training Epoch: 11 | Loss: 0.39555037315200986
Training Epoch: 11 | Loss: 0.3952496873136766
Training Epoch: 11 | Loss: 0.395049431086975
Training Epoch: 11 | Loss: 0.397207010327473
Training Epoch: 11 | Loss: 0.39703330711302315
Validation Loss: 0.3526991754770279
Validation Loss: 0.3943141421100291
Validation Loss: 0.39883210248689155

Training Epoch: 12 | Loss: 0.4314914047718048
Training Epoch: 12 | Loss: 0.3868371598090571
Training Epoch: 12 | Loss: 0.38856242612856834
Training Epoch: 12 | Loss: 0.3872202631346015
Training Epoch: 12 | Loss: 0.3911686793824384
Training Epoch: 12 | Loss: 0.38860968776240556
Training Epoch: 12 | Loss: 0.3889777914011935
Training Epoch: 12 | Loss: 0.3890692071401954
Training Epoch: 12 | Loss: 0.38794656047892856
Validation Loss: 0.310066282749176
Validation Loss: 0.3872361495574512
Validation Loss: 0.3892856497521424

Training Epoch: 13 | Loss: 0.3821685016155243
Training Epoch: 13 | Loss: 0.3745308844833681
Training Epoch: 13 | Loss: 0.3793782204649045
Training Epoch: 13 | Loss: 0.382813722551166
Training Epoch: 13 | Loss: 0.3796134352442481
Training Epoch: 13 | Loss: 0.3827396385936799
Training Epoch: 13 | Loss: 0.38377657815962785
Training Epoch: 13 | Loss: 0.3832151161695428
Training Epoch: 13 | Loss: 0.3823589099601339
Validation Loss: 0.3560328483581543
Validation Loss: 0.38027713012577286
Validation Loss: 0.3880956565673968

Training Epoch: 14 | Loss: 0.3793598785996437
Training Epoch: 14 | Loss: 0.35784969036236847
Training Epoch: 14 | Loss: 0.3651522767002606
Training Epoch: 14 | Loss: 0.3704051074890599
Training Epoch: 14 | Loss: 0.3733929055615182
Training Epoch: 14 | Loss: 0.3763253029971244
Training Epoch: 14 | Loss: 0.3751927242395832
Training Epoch: 14 | Loss: 0.3758088612580903
Training Epoch: 14 | Loss: 0.37512671676570186
Validation Loss: 0.4267762154340744
Validation Loss: 0.38423346539977754
Validation Loss: 0.381282176729755

Training Epoch: 15 | Loss: 0.3339579664170742
Training Epoch: 15 | Loss: 0.35970155721401226
Training Epoch: 15 | Loss: 0.3606903510844678
Training Epoch: 15 | Loss: 0.36472001064729653
Training Epoch: 15 | Loss: 0.3645602031065119
Training Epoch: 15 | Loss: 0.36678034634126755
Training Epoch: 15 | Loss: 0.3669763836241056
Training Epoch: 15 | Loss: 0.3672412055359885
Training Epoch: 15 | Loss: 0.3683695097973619
Validation Loss: 0.26267216354608536
Validation Loss: 0.3727194439103403
Validation Loss: 0.3783007649732615

==> Save checkpoint ...
Training Epoch: 16 | Loss: 0.30674970149993896
Training Epoch: 16 | Loss: 0.3561541551521214
Training Epoch: 16 | Loss: 0.3572018652579826
Training Epoch: 16 | Loss: 0.3598213846179536
Training Epoch: 16 | Loss: 0.35966479776896293
Training Epoch: 16 | Loss: 0.35952077470645455
Training Epoch: 16 | Loss: 0.35991670036325835
Training Epoch: 16 | Loss: 0.3588868684285505
Training Epoch: 16 | Loss: 0.3597886480191041
Validation Loss: 0.27685214579105377
Validation Loss: 0.3678491590267951
Validation Loss: 0.3700407820183839

Training Epoch: 17 | Loss: 0.3422539308667183
Training Epoch: 17 | Loss: 0.35730748121986294
Training Epoch: 17 | Loss: 0.35851911301562445
Training Epoch: 17 | Loss: 0.3572827646713023
Training Epoch: 17 | Loss: 0.3522578866506678
Training Epoch: 17 | Loss: 0.3519202413115494
Training Epoch: 17 | Loss: 0.3530942913107636
Training Epoch: 17 | Loss: 0.35309844952177644
Training Epoch: 17 | Loss: 0.35330805508245466
Validation Loss: 0.20723001286387444
Validation Loss: 0.3753275910742802
Validation Loss: 0.37422424388020786

Training Epoch: 18 | Loss: 0.39521248638629913
Training Epoch: 18 | Loss: 0.3478805925512668
Training Epoch: 18 | Loss: 0.3426209770847316
Training Epoch: 18 | Loss: 0.340943891753093
Training Epoch: 18 | Loss: 0.3431310838929138
Training Epoch: 18 | Loss: 0.34243942256607934
Training Epoch: 18 | Loss: 0.34318975362300674
Training Epoch: 18 | Loss: 0.3437967973146136
Training Epoch: 18 | Loss: 0.34577355643597135
Validation Loss: 0.3826066181063652
Validation Loss: 0.3672924852828578
Validation Loss: 0.36623025378814683

Training Epoch: 19 | Loss: 0.3073446601629257
Training Epoch: 19 | Loss: 0.33250527148420855
Training Epoch: 19 | Loss: 0.335170594827082
Training Epoch: 19 | Loss: 0.33635405995001233
Training Epoch: 19 | Loss: 0.3392018908054157
Training Epoch: 19 | Loss: 0.3410266065103803
Training Epoch: 19 | Loss: 0.3412764217648748
Training Epoch: 19 | Loss: 0.3423627621564647
Training Epoch: 19 | Loss: 0.3420231601969803
Validation Loss: 0.31423647701740265
Validation Loss: 0.35752401441925824
Validation Loss: 0.3596001856436777

Training Epoch: 20 | Loss: 0.3860877454280853
Training Epoch: 20 | Loss: 0.32999779750583785
Training Epoch: 20 | Loss: 0.32870069723483636
Training Epoch: 20 | Loss: 0.32885626222678394
Training Epoch: 20 | Loss: 0.33200666328841016
Training Epoch: 20 | Loss: 0.3311062218833291
Training Epoch: 20 | Loss: 0.3318696294736099
Training Epoch: 20 | Loss: 0.33519176400390144
Training Epoch: 20 | Loss: 0.3357610710537277
Validation Loss: 0.21465758979320526
Validation Loss: 0.35644363711523536
Validation Loss: 0.3522248705802717

==> Save checkpoint ...
Training Epoch: 21 | Loss: 0.31274857372045517
Training Epoch: 21 | Loss: 0.32279719751660185
Training Epoch: 21 | Loss: 0.322412138239513
Training Epoch: 21 | Loss: 0.3243513576550242
Training Epoch: 21 | Loss: 0.323783278660361
Training Epoch: 21 | Loss: 0.3273532495586696
Training Epoch: 21 | Loss: 0.32943108939440197
Training Epoch: 21 | Loss: 0.3290787238452302
Training Epoch: 21 | Loss: 0.32859075853087183
Validation Loss: 0.2791430614888668
Validation Loss: 0.35118620599260425
Validation Loss: 0.34980253128344146

Training Epoch: 22 | Loss: 0.3457212597131729
Training Epoch: 22 | Loss: 0.3339212093465399
Training Epoch: 22 | Loss: 0.3300773247112682
Training Epoch: 22 | Loss: 0.32679922368835373
Training Epoch: 22 | Loss: 0.32710622263575284
Training Epoch: 22 | Loss: 0.32763279758081465
Training Epoch: 22 | Loss: 0.32582963840685747
Training Epoch: 22 | Loss: 0.32456976577331353
Training Epoch: 22 | Loss: 0.3239025587283456
Validation Loss: 0.30293309688568115
Validation Loss: 0.35134477190452046
Validation Loss: 0.347320233392923

Training Epoch: 23 | Loss: 0.4759585112333298
Training Epoch: 23 | Loss: 0.31998793950470367
Training Epoch: 23 | Loss: 0.31569780109088813
Training Epoch: 23 | Loss: 0.3148483546308406
Training Epoch: 23 | Loss: 0.3142646724622966
Training Epoch: 23 | Loss: 0.31610680549979925
Training Epoch: 23 | Loss: 0.31711582352287954
Training Epoch: 23 | Loss: 0.3179677822381343
Training Epoch: 23 | Loss: 0.31878864173120475
Validation Loss: 0.36893339455127716
Validation Loss: 0.3560642976645786
Validation Loss: 0.3448587786684285

Training Epoch: 24 | Loss: 0.4503914788365364
Training Epoch: 24 | Loss: 0.3153245252105269
Training Epoch: 24 | Loss: 0.3192820565691635
Training Epoch: 24 | Loss: 0.3163243493937773
Training Epoch: 24 | Loss: 0.31633862749002223
Training Epoch: 24 | Loss: 0.31409791472578
Training Epoch: 24 | Loss: 0.31276384023283166
Training Epoch: 24 | Loss: 0.31236453547266
Training Epoch: 24 | Loss: 0.31308448862065835
Validation Loss: 0.34656304866075516
Validation Loss: 0.3379156469266013
Validation Loss: 0.33948294449579064

Training Epoch: 25 | Loss: 0.3127756752073765
Training Epoch: 25 | Loss: 0.29997671653728675
Training Epoch: 25 | Loss: 0.3056599346652108
Training Epoch: 25 | Loss: 0.30706529277825473
Training Epoch: 25 | Loss: 0.3050408110189765
Training Epoch: 25 | Loss: 0.30350762811264476
Training Epoch: 25 | Loss: 0.3044883281135073
Training Epoch: 25 | Loss: 0.30487668395212475
Training Epoch: 25 | Loss: 0.30554926942582805
Validation Loss: 0.33203284442424774
Validation Loss: 0.3423319170343699
Validation Loss: 0.34215484981179534

==> Save checkpoint ...
Training Epoch: 26 | Loss: 0.31307752430438995
Training Epoch: 26 | Loss: 0.2972692814240656
Training Epoch: 26 | Loss: 0.29368866996756243
Training Epoch: 26 | Loss: 0.29336126948833663
Training Epoch: 26 | Loss: 0.2948628179264485
Training Epoch: 26 | Loss: 0.29866036693165876
Training Epoch: 26 | Loss: 0.29851522403900915
Training Epoch: 26 | Loss: 0.29922800224683593
Training Epoch: 26 | Loss: 0.30184631581917015
Validation Loss: 0.43703392893075943
Validation Loss: 0.34192440009648256
Validation Loss: 0.34156207877456846

Training Epoch: 27 | Loss: 0.33478380739688873
Training Epoch: 27 | Loss: 0.29046080578671823
Training Epoch: 27 | Loss: 0.2929717932192989
Training Epoch: 27 | Loss: 0.29517065203962134
Training Epoch: 27 | Loss: 0.2961056185630789
Training Epoch: 27 | Loss: 0.29615746300199075
Training Epoch: 27 | Loss: 0.2963838715031867
Training Epoch: 27 | Loss: 0.2973742495488891
Training Epoch: 27 | Loss: 0.2980807667363263
Validation Loss: 0.3366360142827034
Validation Loss: 0.33263027907745674
Validation Loss: 0.333245553947355

Training Epoch: 28 | Loss: 0.30783017724752426
Training Epoch: 28 | Loss: 0.28960340813097385
Training Epoch: 28 | Loss: 0.29317644953875993
Training Epoch: 28 | Loss: 0.2933376395511766
Training Epoch: 28 | Loss: 0.2953501557071979
Training Epoch: 28 | Loss: 0.29476761558797665
Training Epoch: 28 | Loss: 0.29435760148811757
Training Epoch: 28 | Loss: 0.2931413797558034
Training Epoch: 28 | Loss: 0.2930026730538791
Validation Loss: 0.195296723395586
Validation Loss: 0.32698975027640265
Validation Loss: 0.3263613652456459

Training Epoch: 29 | Loss: 0.2951737344264984
Training Epoch: 29 | Loss: 0.2835372447746225
Training Epoch: 29 | Loss: 0.2824759897104098
Training Epoch: 29 | Loss: 0.2841532253582909
Training Epoch: 29 | Loss: 0.28758779980539534
Training Epoch: 29 | Loss: 0.2899313219702113
Training Epoch: 29 | Loss: 0.2897145594446959
Training Epoch: 29 | Loss: 0.2896394856518584
Training Epoch: 29 | Loss: 0.28898139469576684
Validation Loss: 0.27204330265522003
Validation Loss: 0.32915899211006
Validation Loss: 0.32615506634190305

Training Epoch: 30 | Loss: 0.24428006634116173
Training Epoch: 30 | Loss: 0.2718570750243593
Training Epoch: 30 | Loss: 0.2702863705043324
Training Epoch: 30 | Loss: 0.27032334285717075
Training Epoch: 30 | Loss: 0.26864369168989083
Training Epoch: 30 | Loss: 0.2674333558951369
Training Epoch: 30 | Loss: 0.2675871171751455
Training Epoch: 30 | Loss: 0.2669054602462793
Training Epoch: 30 | Loss: 0.2660244478356935
Validation Loss: 0.3717944622039795
Validation Loss: 0.3148409081346328
Validation Loss: 0.30967358284773516

==> Save checkpoint ...
Training Epoch: 31 | Loss: 0.2970181778073311
Training Epoch: 31 | Loss: 0.2606665249913931
Training Epoch: 31 | Loss: 0.2591231791812241
Training Epoch: 31 | Loss: 0.25887481993268496
Training Epoch: 31 | Loss: 0.2586184274916191
Training Epoch: 31 | Loss: 0.25791540578706657
Training Epoch: 31 | Loss: 0.2574760781635163
Training Epoch: 31 | Loss: 0.25821832298286546
Training Epoch: 31 | Loss: 0.257388831031382
Validation Loss: 0.3121841102838516
Validation Loss: 0.3106988008585897
Validation Loss: 0.30833669316338663

Training Epoch: 32 | Loss: 0.26050858199596405
Training Epoch: 32 | Loss: 0.2609228464857777
Training Epoch: 32 | Loss: 0.2588779748468405
Training Epoch: 32 | Loss: 0.2572730357737042
Training Epoch: 32 | Loss: 0.2577622311138676
Training Epoch: 32 | Loss: 0.25650504729645457
Training Epoch: 32 | Loss: 0.25556930965014085
Training Epoch: 32 | Loss: 0.25536886590417374
Training Epoch: 32 | Loss: 0.25539824622828566
Validation Loss: 0.25865933299064636
Validation Loss: 0.31322382626557116
Validation Loss: 0.30408184623243795

Training Epoch: 33 | Loss: 0.20924117043614388
Training Epoch: 33 | Loss: 0.2524676539077617
Training Epoch: 33 | Loss: 0.2473100660118594
Training Epoch: 33 | Loss: 0.25139827937803594
Training Epoch: 33 | Loss: 0.25052842164779093
Training Epoch: 33 | Loss: 0.25119933793451377
Training Epoch: 33 | Loss: 0.2531063593025265
Training Epoch: 33 | Loss: 0.2532691827041234
Training Epoch: 33 | Loss: 0.2535981839445981
Validation Loss: 0.22589239478111267
Validation Loss: 0.2980976272558812
Validation Loss: 0.30654405593983275

Training Epoch: 34 | Loss: 0.27114590257406235
Training Epoch: 34 | Loss: 0.25131853786066616
Training Epoch: 34 | Loss: 0.251709325090792
Training Epoch: 34 | Loss: 0.24961846825539868
Training Epoch: 34 | Loss: 0.25209497713815987
Training Epoch: 34 | Loss: 0.2517349880092039
Training Epoch: 34 | Loss: 0.2537480207925628
Training Epoch: 34 | Loss: 0.2531216763804923
Training Epoch: 34 | Loss: 0.25239232200640865
Validation Loss: 0.20139750093221664
Validation Loss: 0.30462616453371427
Validation Loss: 0.30065195564532754

Training Epoch: 35 | Loss: 0.2687387317419052
Training Epoch: 35 | Loss: 0.24951165619463023
Training Epoch: 35 | Loss: 0.2452961086429915
Training Epoch: 35 | Loss: 0.24591863655370733
Training Epoch: 35 | Loss: 0.24985402822030006
Training Epoch: 35 | Loss: 0.25064105739047426
Training Epoch: 35 | Loss: 0.2507267893027025
Training Epoch: 35 | Loss: 0.24983910819682983
Training Epoch: 35 | Loss: 0.2493342337664798
Validation Loss: 0.42473430931568146
Validation Loss: 0.31095844861304406
Validation Loss: 0.3031060485567768

==> Save checkpoint ...
Training Epoch: 36 | Loss: 0.23735815659165382
Training Epoch: 36 | Loss: 0.24928807306776543
Training Epoch: 36 | Loss: 0.25078866080339274
Training Epoch: 36 | Loss: 0.25205770830478386
Training Epoch: 36 | Loss: 0.24956380777952825
Training Epoch: 36 | Loss: 0.24930453946267417
Training Epoch: 36 | Loss: 0.24797251932137024
Training Epoch: 36 | Loss: 0.2483140252976972
Training Epoch: 36 | Loss: 0.24849626500759456
Validation Loss: 0.18908849731087685
Validation Loss: 0.2951920331999807
Validation Loss: 0.3015097167657976

Training Epoch: 37 | Loss: 0.26439760252833366
Training Epoch: 37 | Loss: 0.24641681506787197
Training Epoch: 37 | Loss: 0.24501394351657055
Training Epoch: 37 | Loss: 0.24566304022167806
Training Epoch: 37 | Loss: 0.24519269193459925
Training Epoch: 37 | Loss: 0.24585732470030436
Training Epoch: 37 | Loss: 0.24464346955649666
Training Epoch: 37 | Loss: 0.2455294574750388
Training Epoch: 37 | Loss: 0.24578469402195138
Validation Loss: 0.3338562995195389
Validation Loss: 0.3059607948001363
Validation Loss: 0.3019666399862339

Training Epoch: 38 | Loss: 0.2184230387210846
Training Epoch: 38 | Loss: 0.24470465873727704
Training Epoch: 38 | Loss: 0.242397901337983
Training Epoch: 38 | Loss: 0.24326785694052808
Training Epoch: 38 | Loss: 0.2469572474218515
Training Epoch: 38 | Loss: 0.24872455536248442
Training Epoch: 38 | Loss: 0.24803284043988552
Training Epoch: 38 | Loss: 0.24684038504522385
Training Epoch: 38 | Loss: 0.24692179895844427
Validation Loss: 0.3018714711070061
Validation Loss: 0.29974730978581576
Validation Loss: 0.30311700028937255

Training Epoch: 39 | Loss: 0.21289097517728806
Training Epoch: 39 | Loss: 0.24202696663687134
Training Epoch: 39 | Loss: 0.2417391707092079
Training Epoch: 39 | Loss: 0.2432258828880383
Training Epoch: 39 | Loss: 0.24407317037427068
Training Epoch: 39 | Loss: 0.24609750286934381
Training Epoch: 39 | Loss: 0.24550440611810534
Training Epoch: 39 | Loss: 0.24513743473974173
Training Epoch: 39 | Loss: 0.24572628803118673
Validation Loss: 0.24020060896873474
Validation Loss: 0.3013173346177186
Validation Loss: 0.29831915967796574

Training Epoch: 40 | Loss: 0.2619696445763111
Training Epoch: 40 | Loss: 0.24151852109128297
Training Epoch: 40 | Loss: 0.24462382663134022
Training Epoch: 40 | Loss: 0.24261202848828908
Training Epoch: 40 | Loss: 0.24322829341186103
Training Epoch: 40 | Loss: 0.24300686001197663
Training Epoch: 40 | Loss: 0.24341363779047562
Training Epoch: 40 | Loss: 0.24371828255476097
Training Epoch: 40 | Loss: 0.24459331460092473
Validation Loss: 0.38210147619247437
Validation Loss: 0.30362081689999837
Validation Loss: 0.2999821863141819

==> Save checkpoint ...
Training Epoch: 41 | Loss: 0.20062173157930374
Training Epoch: 41 | Loss: 0.23778990414546858
Training Epoch: 41 | Loss: 0.24143017075066245
Training Epoch: 41 | Loss: 0.24074335563370952
Training Epoch: 41 | Loss: 0.2405935986213702
Training Epoch: 41 | Loss: 0.2407883104539203
Training Epoch: 41 | Loss: 0.2420920209878569
Training Epoch: 41 | Loss: 0.24289181281263791
Training Epoch: 41 | Loss: 0.2438139992913745
Validation Loss: 0.4364687204360962
Validation Loss: 0.3045362644266374
Validation Loss: 0.30180817393039294

Training Epoch: 42 | Loss: 0.29117926210165024
Training Epoch: 42 | Loss: 0.23641526889019082
Training Epoch: 42 | Loss: 0.23634897815573275
Training Epoch: 42 | Loss: 0.238038705470059
Training Epoch: 42 | Loss: 0.23924588817554965
Training Epoch: 42 | Loss: 0.24010992449096696
Training Epoch: 42 | Loss: 0.23986014470879527
Training Epoch: 42 | Loss: 0.24076877577700645
Training Epoch: 42 | Loss: 0.2418142373484098
Validation Loss: 0.36436599493026733
Validation Loss: 0.2999118119109385
Validation Loss: 0.2993019786084173

Training Epoch: 43 | Loss: 0.24951355904340744
Training Epoch: 43 | Loss: 0.2421750685034117
Training Epoch: 43 | Loss: 0.2375317717814327
Training Epoch: 43 | Loss: 0.23644150364710842
Training Epoch: 43 | Loss: 0.23843724864472327
Training Epoch: 43 | Loss: 0.23964650772080687
Training Epoch: 43 | Loss: 0.23993039737996366
Training Epoch: 43 | Loss: 0.24094964031358587
Training Epoch: 43 | Loss: 0.2400979840088538
Validation Loss: 0.2984454706311226
Validation Loss: 0.3055299097247938
Validation Loss: 0.30082630339212973

Training Epoch: 44 | Loss: 0.316824346780777
Training Epoch: 44 | Loss: 0.23682735432492624
Training Epoch: 44 | Loss: 0.23513138059767622
Training Epoch: 44 | Loss: 0.23450681185380762
Training Epoch: 44 | Loss: 0.2358715643739314
Training Epoch: 44 | Loss: 0.2382067383049491
Training Epoch: 44 | Loss: 0.23986382598984063
Training Epoch: 44 | Loss: 0.2395088709332846
Training Epoch: 44 | Loss: 0.24008132920097025
Validation Loss: 0.24577998742461205
Validation Loss: 0.29703560962092757
Validation Loss: 0.29924016727588665

Training Epoch: 45 | Loss: 0.3661671131849289
Training Epoch: 45 | Loss: 0.2442224483273112
Training Epoch: 45 | Loss: 0.23891028784104248
Training Epoch: 45 | Loss: 0.2400216186957502
Training Epoch: 45 | Loss: 0.23878779264162306
Training Epoch: 45 | Loss: 0.2402663247440449
Training Epoch: 45 | Loss: 0.240373629416508
Training Epoch: 45 | Loss: 0.24013779153741802
Training Epoch: 45 | Loss: 0.24065300022320504
Validation Loss: 0.3339233584702015
Validation Loss: 0.3076019104902107
Validation Loss: 0.29773066456045083

==> Save checkpoint ...
Training Epoch: 46 | Loss: 0.282657727599144
Training Epoch: 46 | Loss: 0.224532035649708
Training Epoch: 46 | Loss: 0.22745193083265527
Training Epoch: 46 | Loss: 0.2324735442133144
Training Epoch: 46 | Loss: 0.23529502030396995
Training Epoch: 46 | Loss: 0.23676549238031971
Training Epoch: 46 | Loss: 0.23677939788350053
Training Epoch: 46 | Loss: 0.2379311526940867
Training Epoch: 46 | Loss: 0.23795240695649914
Validation Loss: 0.28476811945438385
Validation Loss: 0.3013544778828279
Validation Loss: 0.29600257390359447

Training Epoch: 47 | Loss: 0.2884044870734215
Training Epoch: 47 | Loss: 0.2413566109752006
Training Epoch: 47 | Loss: 0.24387059612802012
Training Epoch: 47 | Loss: 0.24172195398010488
Training Epoch: 47 | Loss: 0.24171331647476949
Training Epoch: 47 | Loss: 0.24211222922685974
Training Epoch: 47 | Loss: 0.24098835790377984
Training Epoch: 47 | Loss: 0.2390546407630287
Training Epoch: 47 | Loss: 0.23803228406833205
Validation Loss: 0.3044200763106346
Validation Loss: 0.3030736153890001
Validation Loss: 0.2963543715168588

Training Epoch: 48 | Loss: 0.2626947984099388
Training Epoch: 48 | Loss: 0.23740938870180953
Training Epoch: 48 | Loss: 0.23586122667537399
Training Epoch: 48 | Loss: 0.23486617063961157
Training Epoch: 48 | Loss: 0.23552040707905245
Training Epoch: 48 | Loss: 0.23576171621828973
Training Epoch: 48 | Loss: 0.23634818245884584
Training Epoch: 48 | Loss: 0.23853994994430927
Training Epoch: 48 | Loss: 0.23829960224733743
Validation Loss: 0.3669806942343712
Validation Loss: 0.309393393705682
Validation Loss: 0.29670623768658483

Training Epoch: 49 | Loss: 0.19558685645461082
Training Epoch: 49 | Loss: 0.23129398652380057
Training Epoch: 49 | Loss: 0.22969538079046492
Training Epoch: 49 | Loss: 0.23147055220811866
Training Epoch: 49 | Loss: 0.23204951247483716
Training Epoch: 49 | Loss: 0.23284181221546288
Training Epoch: 49 | Loss: 0.2342748757724506
Training Epoch: 49 | Loss: 0.23508017198760567
Training Epoch: 49 | Loss: 0.23628878600421024
Validation Loss: 0.3778623044490814
Validation Loss: 0.29228203286333837
Validation Loss: 0.2954610703670563

Training Epoch: 50 | Loss: 0.23417431116104126
Training Epoch: 50 | Loss: 0.22796453839850309
Training Epoch: 50 | Loss: 0.23301005228167743
Training Epoch: 50 | Loss: 0.23517560439673174
Training Epoch: 50 | Loss: 0.23436744393608963
Training Epoch: 50 | Loss: 0.23544274902569795
Training Epoch: 50 | Loss: 0.23451213791235018
Training Epoch: 50 | Loss: 0.23515543915310105
Training Epoch: 50 | Loss: 0.2351893817473403
Validation Loss: 0.24611204117536545
Validation Loss: 0.29495226165814564
Validation Loss: 0.2941255413774234

==> Save checkpoint ...
Training Epoch: 51 | Loss: 0.14392943494021893
Training Epoch: 51 | Loss: 0.2312094275977942
Training Epoch: 51 | Loss: 0.23114411139035995
Training Epoch: 51 | Loss: 0.23329867114408864
Training Epoch: 51 | Loss: 0.233032900347674
Training Epoch: 51 | Loss: 0.23314161665232
Training Epoch: 51 | Loss: 0.23278338476060928
Training Epoch: 51 | Loss: 0.23327378866750317
Training Epoch: 51 | Loss: 0.233779489080167
Validation Loss: 0.2216041386127472
Validation Loss: 0.2985096266954252
Validation Loss: 0.29621995750128927

Training Epoch: 52 | Loss: 0.2608303502202034
Training Epoch: 52 | Loss: 0.23303703613357968
Training Epoch: 52 | Loss: 0.2324807588659709
Training Epoch: 52 | Loss: 0.2330954745349991
Training Epoch: 52 | Loss: 0.23191740608163308
Training Epoch: 52 | Loss: 0.23207532844976514
Training Epoch: 52 | Loss: 0.23244816701729068
Training Epoch: 52 | Loss: 0.2335657769822105
Training Epoch: 52 | Loss: 0.23471546382381675
Validation Loss: 0.27471456676721573
Validation Loss: 0.2915855972926215
Validation Loss: 0.29594454263795666

Training Epoch: 53 | Loss: 0.23646311461925507
Training Epoch: 53 | Loss: 0.22859667756106003
Training Epoch: 53 | Loss: 0.22761049215213872
Training Epoch: 53 | Loss: 0.23309751917481225
Training Epoch: 53 | Loss: 0.23157845938257743
Training Epoch: 53 | Loss: 0.2324296003932546
Training Epoch: 53 | Loss: 0.23345086145557203
Training Epoch: 53 | Loss: 0.23283135095417246
Training Epoch: 53 | Loss: 0.2329388072321217
Validation Loss: 0.35207661241292953
Validation Loss: 0.297228466166128
Validation Loss: 0.2938719245961946

Training Epoch: 54 | Loss: 0.3073984831571579
Training Epoch: 54 | Loss: 0.23920216581018844
Training Epoch: 54 | Loss: 0.23494934017274213
Training Epoch: 54 | Loss: 0.23280539486148824
Training Epoch: 54 | Loss: 0.23115073167196384
Training Epoch: 54 | Loss: 0.23111147159885265
Training Epoch: 54 | Loss: 0.23156517481868358
Training Epoch: 54 | Loss: 0.23257705772537393
Training Epoch: 54 | Loss: 0.2328497620041339
Validation Loss: 0.18692799285054207
Validation Loss: 0.29617089697039956
Validation Loss: 0.29345627584082273

Training Epoch: 55 | Loss: 0.24501852691173553
Training Epoch: 55 | Loss: 0.23885285863560615
Training Epoch: 55 | Loss: 0.2295835109529507
Training Epoch: 55 | Loss: 0.2290364239934176
Training Epoch: 55 | Loss: 0.2302152495180951
Training Epoch: 55 | Loss: 0.23164299025224475
Training Epoch: 55 | Loss: 0.23242980465230945
Training Epoch: 55 | Loss: 0.23295523955907868
Training Epoch: 55 | Loss: 0.2324931775539481
Validation Loss: 0.31123657524585724
Validation Loss: 0.2966882404271919
Validation Loss: 0.2932426994342116

==> Save checkpoint ...
Training Epoch: 56 | Loss: 0.23276002705097198
Training Epoch: 56 | Loss: 0.22837651041474674
Training Epoch: 56 | Loss: 0.2314343825075312
Training Epoch: 56 | Loss: 0.23223145232161513
Training Epoch: 56 | Loss: 0.23157952913313062
Training Epoch: 56 | Loss: 0.2343301742752185
Training Epoch: 56 | Loss: 0.23276651121161493
Training Epoch: 56 | Loss: 0.23265273567055286
Training Epoch: 56 | Loss: 0.23305091069669423
Validation Loss: 0.32435330748558044
Validation Loss: 0.2934069454227344
Validation Loss: 0.2952888100338516

Training Epoch: 57 | Loss: 0.2773095667362213
Training Epoch: 57 | Loss: 0.22999209141598478
Training Epoch: 57 | Loss: 0.23162761192527873
Training Epoch: 57 | Loss: 0.23325373192141421
Training Epoch: 57 | Loss: 0.2360906460347987
Training Epoch: 57 | Loss: 0.23564325582734244
Training Epoch: 57 | Loss: 0.2351500439843451
Training Epoch: 57 | Loss: 0.23390008239593682
Training Epoch: 57 | Loss: 0.2334096086445205
Validation Loss: 0.3134240061044693
Validation Loss: 0.3009782881466764
Validation Loss: 0.29559614367560666

Training Epoch: 58 | Loss: 0.1845977045595646
Training Epoch: 58 | Loss: 0.23536177792835353
Training Epoch: 58 | Loss: 0.23420928882907577
Training Epoch: 58 | Loss: 0.23317638151595166
Training Epoch: 58 | Loss: 0.23279861882886388
Training Epoch: 58 | Loss: 0.2337026727309603
Training Epoch: 58 | Loss: 0.232328208333839
Training Epoch: 58 | Loss: 0.23224112208927325
Training Epoch: 58 | Loss: 0.23173082308534454
Validation Loss: 0.2708227336406708
Validation Loss: 0.29013263389910804
Validation Loss: 0.29171005364007024

Training Epoch: 59 | Loss: 0.20847874134778976
Training Epoch: 59 | Loss: 0.23297256729242824
Training Epoch: 59 | Loss: 0.22971035550297492
Training Epoch: 59 | Loss: 0.22964025980659894
Training Epoch: 59 | Loss: 0.23101438365486496
Training Epoch: 59 | Loss: 0.23080000272411072
Training Epoch: 59 | Loss: 0.2317933988092644
Training Epoch: 59 | Loss: 0.23139593833140742
Training Epoch: 59 | Loss: 0.2312090148435401
Validation Loss: 0.24306372180581093
Validation Loss: 0.2928969910054809
Validation Loss: 0.293815576114613

Training Epoch: 60 | Loss: 0.21829858422279358
Training Epoch: 60 | Loss: 0.22731483325657278
Training Epoch: 60 | Loss: 0.22791172154433098
Training Epoch: 60 | Loss: 0.22650612776857673
Training Epoch: 60 | Loss: 0.22974509465742735
Training Epoch: 60 | Loss: 0.22911280833794448
Training Epoch: 60 | Loss: 0.2302315212420487
Training Epoch: 60 | Loss: 0.23163335407936625
Training Epoch: 60 | Loss: 0.23216161305333644
Validation Loss: 0.2527664117515087
Validation Loss: 0.2934745870493721
Validation Loss: 0.2917910217775486

==> Save checkpoint ...
Training Epoch: 61 | Loss: 0.3566186875104904
Training Epoch: 61 | Loss: 0.23078713416684382
Training Epoch: 61 | Loss: 0.23004130854164784
Training Epoch: 61 | Loss: 0.23082107699095608
Training Epoch: 61 | Loss: 0.23216218025216884
Training Epoch: 61 | Loss: 0.2325870822687557
Training Epoch: 61 | Loss: 0.232824078032719
Training Epoch: 61 | Loss: 0.23214721113055434
Training Epoch: 61 | Loss: 0.23238010579527132
Validation Loss: 0.34319449961185455
Validation Loss: 0.29600802720478264
Validation Loss: 0.2936135573840853

Training Epoch: 62 | Loss: 0.2753066122531891
Training Epoch: 62 | Loss: 0.22674032802333927
Training Epoch: 62 | Loss: 0.22662003528308217
Training Epoch: 62 | Loss: 0.22941692010112774
Training Epoch: 62 | Loss: 0.23149709158258844
Training Epoch: 62 | Loss: 0.23218058769827238
Training Epoch: 62 | Loss: 0.23221111893591884
Training Epoch: 62 | Loss: 0.23225856376293721
Training Epoch: 62 | Loss: 0.2317962149988288
Validation Loss: 0.18404176086187363
Validation Loss: 0.2968165004939431
Validation Loss: 0.2929449085776337

Training Epoch: 63 | Loss: 0.31145817786455154
Training Epoch: 63 | Loss: 0.24247203398459027
Training Epoch: 63 | Loss: 0.23702399087004103
Training Epoch: 63 | Loss: 0.2365666343505646
Training Epoch: 63 | Loss: 0.23713703986090096
Training Epoch: 63 | Loss: 0.23769952008638257
Training Epoch: 63 | Loss: 0.23552293743405137
Training Epoch: 63 | Loss: 0.23396813606022301
Training Epoch: 63 | Loss: 0.23373444753346706
Validation Loss: 0.2789260521531105
Validation Loss: 0.28851476750604
Validation Loss: 0.294911293248039

Training Epoch: 64 | Loss: 0.21834057569503784
Training Epoch: 64 | Loss: 0.23334699561173963
Training Epoch: 64 | Loss: 0.23317540651974986
Training Epoch: 64 | Loss: 0.2314769004802668
Training Epoch: 64 | Loss: 0.23095114656870352
Training Epoch: 64 | Loss: 0.23157620822969907
Training Epoch: 64 | Loss: 0.2316854155301651
Training Epoch: 64 | Loss: 0.23185822916364618
Training Epoch: 64 | Loss: 0.23227009492067063
Validation Loss: 0.3517029583454132
Validation Loss: 0.2943136082722409
Validation Loss: 0.2932001356109606

Training Epoch: 65 | Loss: 0.18757560104131699
Training Epoch: 65 | Loss: 0.22883189803376647
Training Epoch: 65 | Loss: 0.22855103106715194
Training Epoch: 65 | Loss: 0.22953924745865834
Training Epoch: 65 | Loss: 0.2283436270370299
Training Epoch: 65 | Loss: 0.23025235184979534
Training Epoch: 65 | Loss: 0.23043456370826074
Training Epoch: 65 | Loss: 0.2321327211157274
Training Epoch: 65 | Loss: 0.23170226691441886
Validation Loss: 0.23542512953281403
Validation Loss: 0.2962564226461224
Validation Loss: 0.29436679963782353

==> Save checkpoint ...
Training Epoch: 66 | Loss: 0.23511037230491638
Training Epoch: 66 | Loss: 0.2311547566020843
Training Epoch: 66 | Loss: 0.23543967045287587
Training Epoch: 66 | Loss: 0.23379892078027179
Training Epoch: 66 | Loss: 0.2322217295842798
Training Epoch: 66 | Loss: 0.2308345794484406
Training Epoch: 66 | Loss: 0.2306811966020583
Training Epoch: 66 | Loss: 0.23006446327424254
Training Epoch: 66 | Loss: 0.2302637207862478
Validation Loss: 0.3050466701388359
Validation Loss: 0.2860460070764074
Validation Loss: 0.29165979333926195

Training Epoch: 67 | Loss: 0.19749432429671288
Training Epoch: 67 | Loss: 0.23608486330376402
Training Epoch: 67 | Loss: 0.23625120600287
Training Epoch: 67 | Loss: 0.23690687411424527
Training Epoch: 67 | Loss: 0.23420953019487292
Training Epoch: 67 | Loss: 0.23344884859676845
Training Epoch: 67 | Loss: 0.23246701513595272
Training Epoch: 67 | Loss: 0.23226125565451836
Training Epoch: 67 | Loss: 0.23142053559887574
Validation Loss: 0.24628645926713943
Validation Loss: 0.288476633129291
Validation Loss: 0.2923214738141393

Training Epoch: 68 | Loss: 0.18159855529665947
Training Epoch: 68 | Loss: 0.22565096111433341
Training Epoch: 68 | Loss: 0.2305091048187729
Training Epoch: 68 | Loss: 0.22937743216010423
Training Epoch: 68 | Loss: 0.23039507892846764
Training Epoch: 68 | Loss: 0.2285239006617588
Training Epoch: 68 | Loss: 0.22878416634773752
Training Epoch: 68 | Loss: 0.2293835730556287
Training Epoch: 68 | Loss: 0.23051062510691853
Validation Loss: 0.2924227863550186
Validation Loss: 0.29040030727513355
Validation Loss: 0.29340219563475595

Training Epoch: 69 | Loss: 0.18465274199843407
Training Epoch: 69 | Loss: 0.22416413931342044
Training Epoch: 69 | Loss: 0.22916031238711
Training Epoch: 69 | Loss: 0.22846547956036967
Training Epoch: 69 | Loss: 0.228896714143102
Training Epoch: 69 | Loss: 0.22944748816182634
Training Epoch: 69 | Loss: 0.22985334628371648
Training Epoch: 69 | Loss: 0.22950469217556774
Training Epoch: 69 | Loss: 0.2304100093249227
Validation Loss: 0.2556786723434925
Validation Loss: 0.28607392952878874
Validation Loss: 0.2924274574427759

Training Epoch: 70 | Loss: 0.3200056329369545
Training Epoch: 70 | Loss: 0.22609618184442568
Training Epoch: 70 | Loss: 0.23387879932957206
Training Epoch: 70 | Loss: 0.23113517039625647
Training Epoch: 70 | Loss: 0.232057679916019
Training Epoch: 70 | Loss: 0.2321161394492684
Training Epoch: 70 | Loss: 0.23342708556040404
Training Epoch: 70 | Loss: 0.2323658713837089
Training Epoch: 70 | Loss: 0.2315307537782077
Validation Loss: 0.25989557802677155
Validation Loss: 0.2897831129629423
Validation Loss: 0.2938039111371954

==> Save checkpoint ...
Training Epoch: 71 | Loss: 0.2564976215362549
Training Epoch: 71 | Loss: 0.23418624680673722
Training Epoch: 71 | Loss: 0.23128659999118514
Training Epoch: 71 | Loss: 0.23278647950816392
Training Epoch: 71 | Loss: 0.23165147225755706
Training Epoch: 71 | Loss: 0.2311473538032073
Training Epoch: 71 | Loss: 0.23153164068518978
Training Epoch: 71 | Loss: 0.2308060566545298
Training Epoch: 71 | Loss: 0.2303764462777961
Validation Loss: 0.2989402115345001
Validation Loss: 0.3024850970705842
Validation Loss: 0.29356741285257376

Training Epoch: 72 | Loss: 0.18462886288762093
Training Epoch: 72 | Loss: 0.23138117292287327
Training Epoch: 72 | Loss: 0.23323448429542099
Training Epoch: 72 | Loss: 0.23173298806174847
Training Epoch: 72 | Loss: 0.23135015649948631
Training Epoch: 72 | Loss: 0.23028447551879577
Training Epoch: 72 | Loss: 0.2298124839494411
Training Epoch: 72 | Loss: 0.2295067461204852
Training Epoch: 72 | Loss: 0.23102572914933817
Validation Loss: 0.32786940038204193
Validation Loss: 0.28639241389118797
Validation Loss: 0.2913018326502089

Training Epoch: 73 | Loss: 0.2596135586500168
Training Epoch: 73 | Loss: 0.23404671937817395
Training Epoch: 73 | Loss: 0.23026812838307067
Training Epoch: 73 | Loss: 0.22945809049339982
Training Epoch: 73 | Loss: 0.22970210620088322
Training Epoch: 73 | Loss: 0.22940187208250373
Training Epoch: 73 | Loss: 0.22994005053727182
Training Epoch: 73 | Loss: 0.2307455758358247
Training Epoch: 73 | Loss: 0.22998861419490438
Validation Loss: 0.27780747041106224
Validation Loss: 0.2839207038799725
Validation Loss: 0.2935550333329694

Training Epoch: 74 | Loss: 0.22975051775574684
Training Epoch: 74 | Loss: 0.22739694247225134
Training Epoch: 74 | Loss: 0.2296914907533731
Training Epoch: 74 | Loss: 0.2297338165058151
Training Epoch: 74 | Loss: 0.2284219703007666
Training Epoch: 74 | Loss: 0.23055129757377796
Training Epoch: 74 | Loss: 0.23167924409710527
Training Epoch: 74 | Loss: 0.2311400091554571
Training Epoch: 74 | Loss: 0.2311328731119149
Validation Loss: 0.30070754885673523
Validation Loss: 0.29355609887233464
Validation Loss: 0.2915230914765033

Training Epoch: 75 | Loss: 0.19894511252641678
Training Epoch: 75 | Loss: 0.23471626104547247
Training Epoch: 75 | Loss: 0.23739341793776447
Training Epoch: 75 | Loss: 0.2356893895534285
Training Epoch: 75 | Loss: 0.23267916758588872
Training Epoch: 75 | Loss: 0.23310250503395846
Training Epoch: 75 | Loss: 0.23200457415135947
Training Epoch: 75 | Loss: 0.2319373438020533
Training Epoch: 75 | Loss: 0.23155440308023406
Validation Loss: 0.2489985153079033
Validation Loss: 0.29653201445863386
Validation Loss: 0.29360253307319695

==> Save checkpoint ...
Training Epoch: 76 | Loss: 0.23864859342575073
Training Epoch: 76 | Loss: 0.22333143712344147
Training Epoch: 76 | Loss: 0.22526899652916993
Training Epoch: 76 | Loss: 0.22858185209086368
Training Epoch: 76 | Loss: 0.2294458332715412
Training Epoch: 76 | Loss: 0.228865456185536
Training Epoch: 76 | Loss: 0.22970369542188038
Training Epoch: 76 | Loss: 0.22977908423832072
Training Epoch: 76 | Loss: 0.22955485948648643
Validation Loss: 0.2991715036332607
Validation Loss: 0.2929400198973051
Validation Loss: 0.2931976173981209

Training Epoch: 77 | Loss: 0.2475377321243286
Training Epoch: 77 | Loss: 0.22540867905879375
Training Epoch: 77 | Loss: 0.23080716169073215
Training Epoch: 77 | Loss: 0.23149255208324554
Training Epoch: 77 | Loss: 0.22864522569884832
Training Epoch: 77 | Loss: 0.23095021312480082
Training Epoch: 77 | Loss: 0.2305520828069496
Training Epoch: 77 | Loss: 0.22983430883449937
Training Epoch: 77 | Loss: 0.23008781395266564
Validation Loss: 0.29212041199207306
Validation Loss: 0.28373213923803653
Validation Loss: 0.29142084805786017

Training Epoch: 78 | Loss: 0.2500742897391319
Training Epoch: 78 | Loss: 0.238562023894179
Training Epoch: 78 | Loss: 0.23341258620815492
Training Epoch: 78 | Loss: 0.23256656057835615
Training Epoch: 78 | Loss: 0.23187613997729192
Training Epoch: 78 | Loss: 0.23098137875844144
Training Epoch: 78 | Loss: 0.23073225106715461
Training Epoch: 78 | Loss: 0.23121957299957177
Training Epoch: 78 | Loss: 0.230640810331825
Validation Loss: 0.33757229894399643
Validation Loss: 0.29995399512498094
Validation Loss: 0.2955897046225284

Training Epoch: 79 | Loss: 0.21011920645833015
Training Epoch: 79 | Loss: 0.2371042678593704
Training Epoch: 79 | Loss: 0.23299137213781698
Training Epoch: 79 | Loss: 0.23104967575433644
Training Epoch: 79 | Loss: 0.23016479325729267
Training Epoch: 79 | Loss: 0.23136376473539605
Training Epoch: 79 | Loss: 0.23087773761540006
Training Epoch: 79 | Loss: 0.23061909494966737
Training Epoch: 79 | Loss: 0.23018283237669426
Validation Loss: 0.29446879774332047
Validation Loss: 0.29481927683521614
Validation Loss: 0.29136484152456715

==> Save checkpoint ...